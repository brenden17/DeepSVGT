"""
https://towardsdatascience.com/building-a-convolutional-vae-in-pytorch-a0f54c947f71
"""
import torch
import torch.nn as nn
import torch.nn.functional as F

from utils import plot_latent2
from datasets import build_dataloaders


torch.manual_seed(0)

"""
class Encoder(nn.Module):
    def __init__(self, z_dim):
        super(Encoder, self).__init__()
        self.conv1 = nn.Conv1d(1, 16, 8, 2, padding=3)
        self.conv2 = nn.Conv1d(16, 16, 8, 2, padding=3)
        self.conv3 = nn.Conv1d(16, 32, 8, 2, padding=3)
        self.conv4 = nn.Conv1d(32, 32, 8, 2, padding=3)
        self.fc1 = nn.Linear(32*21, 64)
        self.fc2 = nn.Linear(64, 16)
        self.fc21 = nn.Linear(16, z_dim)
        self.fc22 = nn.Linear(16, z_dim)
        self.relu = nn.ReLU()


    def forward(self, x):
        x = x.view(-1,1,336)
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = self.relu(self.conv3(x))
        x = self.relu(self.conv4(x))
        x = x.view(-1, 672)
        x = self.relu(self.fc1(x))
        x = F.dropout(x, 0.3)
        x = self.relu(self.fc2(x))
        z_loc = self.fc21(x)
        z_scale = self.fc22(x)
        return z_loc, z_scale

class Decoder(nn.Module):
    def __init__(self, z_dim):
        super(Decoder, self).__init__()
        self.fc1 = nn.Linear(z_dim, 672)
        self.conv1 = nn.ConvTranspose1d(32, 32, 8, 2, padding=3)
        self.conv2 = nn.ConvTranspose1d(32, 32, 8, 2, padding=3)
        self.conv3 = nn.ConvTranspose1d(32, 16, 8, 2, padding=3)
        self.conv4 = nn.ConvTranspose1d(16, 16, 8, 2, padding=3)
        self.conv5 = nn.ConvTranspose1d(16, 1, 7, 1, padding=3)
        self.relu = nn.ReLU()

    def forward(self, z):
        z = self.relu(self.fc1(z))
        z = z.view(-1, 32, 21)
        z = self.relu(self.conv1(z))
        z = self.relu(self.conv2(z))
        z = self.relu(self.conv3(z))
        z = self.relu(self.conv4(z))
        z = self.conv5(z)
        recon = torch.sigmoid(z)
        return recon


class VAE(nn.Module):
    def __init__(self, z_dim=2):
        super(VAE, self).__init__()
        self.encoder = Encoder(z_dim)
        self.decoder = Decoder(z_dim)
        self.cuda()
        self.z_dim = z_dim

    def reparameterize(self, z_loc, z_scale):
        std = z_scale.mul(0.5).exp_()
        epsilon = torch.randn(*z_loc.size()).to(device)
        z = z_loc + std * epsilon
        return z

vae = VAE()
optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)

def loss_fn(recon_x, x, z_loc, z_scale):
    MSE = F.mse_loss(recon_x, x, size_average=False)*10
    KLD = -0.5 * torch.mean(1 + z_scale - z_loc.pow(2) - z_scale.exp())
    return MSE + KLD


for epoch in range(1000):
    for x, _ in train_dl:
        x = x.cuda()
        z_loc, z_scale = vae.encoder(x)
        z = vae.reparameterize(z_loc, z_scale)
        recon = vae.decoder(z)
        loss = loss_fn(recon, x, z_loc, z_scale)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    vae.eval()
    with torch.no_grad():
        for i, (x, _) in enumerate(test_dl):
            x = x.cuda()
            z_loc, z_scale = vae.encoder(x)
            z = vae.reparameterize(z_loc, z_scale)
            recon = vae.decoder(z)
            test_loss = loss_fn(recon, x, z_loc, z_scale)
    normalizer_test = len(test_dl.dataset)
    total_epoch_loss_test = test_loss / normalizer_test
    #my crappy early stopping implementation
    if epoch == 0:
        loss_test_history = total_epoch_loss_test.item()
        patience = 0
    else:
        loss_test_history = np.append(loss_test_history, total_epoch_loss_test.item())

    if total_epoch_loss_test.item() < 0.000001+np.min(loss_test_history):
        patience = 0
        torch.save(vae.decoder.state_dict(), "~/best_decoder_model.pt")
        torch.save(vae.encoder.state_dict(), "~/best_encoder_model.pt")
    else:
        patience +=1

    print(epoch, patience, total_epoch_loss_test.item(), np.min(loss_test_history))

    if patience == 32:
        break
===================================
"""

"""
A Convolutional Variational Autoencoder
# """
# class VAE(nn.Module):
    # def __init__(self, imgChannels=1, featureDim=32*20*20, zDim=256):
    #     super(VAE, self).__init__()

    #     # Initializing the 2 convolutional layers and 2 full-connected layers for the encoder
    #     self.encConv1 = nn.Conv1d(imgChannels, 16, 5)
    #     self.encConv2 = nn.Conv1d(16, 32, 5)
    #     self.encFC1 = nn.Linear(featureDim, zDim)
    #     self.encFC2 = nn.Linear(featureDim, zDim)

    #     # Initializing the fully-connected layer and 2 convolutional layers for decoder
    #     self.decFC1 = nn.Linear(zDim, featureDim)
    #     self.decConv1 = nn.ConvTranspose1d(32, 16, 5)
    #     self.decConv2 = nn.ConvTranspose1d(16, imgChannels, 5)

    # def encoder(self, x):

    #     # Input is fed into 2 convolutional layers sequentially
    #     # The output feature map are fed into 2 fully-connected layers to predict mean (mu) and variance (logVar)
    #     # Mu and logVar are used for generating middle representation z and KL divergence loss
    #     x = F.relu(self.encConv1(x))
    #     x = F.relu(self.encConv2(x))
    #     x = x.view(-1, 32*20*20)
    #     mu = self.encFC1(x)
    #     logVar = self.encFC2(x)
    #     return mu, logVar

    # def reparameterize(self, mu, logVar):

    #     #Reparameterization takes in the input mu and logVar and sample the mu + std * eps
    #     std = torch.exp(logVar/2)
    #     eps = torch.randn_like(std)
    #     return mu + std * eps

    # def decoder(self, z):

    #     # z is fed back into a fully-connected layers and then into two transpose convolutional layers
    #     # The generated output is the same size of the original input
    #     x = F.relu(self.decFC1(z))
    #     x = x.view(-1, 32, 20, 20)
    #     x = F.relu(self.decConv1(x))
    #     x = torch.sigmoid(self.decConv2(x))
    #     return x

    # def forward(self, x):

    #     # The entire pipeline of the VAE: encoder -> reparameterization -> decoder
    #     # output, mu, and logVar are returned for loss computation
    #     mu, logVar = self.encoder(x)
    #     z = self.reparameterize(mu, logVar)
    #     out = self.decoder(z)
    #     return out, mu, logVar



# class Encoder(nn.Module):
#     def __init__(self, z_dim):
#         super(Encoder, self).__init__()
#         self.conv1 = nn.Conv1d(1, 16, 8, 2, padding=3)
#         self.conv2 = nn.Conv1d(16, 16, 8, 2, padding=3)
#         self.conv3 = nn.Conv1d(16, 32, 8, 2, padding=3)
#         self.conv4 = nn.Conv1d(32, 32, 8, 2, padding=3)

#         self.fc1 = nn.Linear(32*21, 64)
#         self.fc2 = nn.Linear(64, 16)
#         self.fc21 = nn.Linear(16, z_dim)
#         self.fc22 = nn.Linear(16, z_dim)
#         self.relu = nn.ReLU()


#     def forward(self, x):
#         # x = x.view(-1,1,336)
#         x = x.view(-1,1,1200)
#         x = self.relu(self.conv1(x))
#         x = self.relu(self.conv2(x))
#         x = self.relu(self.conv3(x))
#         x = self.relu(self.conv4(x))
#         x = x.view(-1, 672)
#         x = self.relu(self.fc1(x))
#         x = F.dropout(x, 0.3)
#         x = self.relu(self.fc2(x))
#         z_loc = self.fc21(x)
#         z_scale = self.fc22(x)
#         return z_loc, z_scale

# class Decoder(nn.Module):
#     def __init__(self, z_dim):
#         super(Decoder, self).__init__()
#         self.fc1 = nn.Linear(z_dim, 672)
#         self.conv1 = nn.ConvTranspose1d(32, 32, 8, 2, padding=3)
#         self.conv2 = nn.ConvTranspose1d(32, 32, 8, 2, padding=3)
#         self.conv3 = nn.ConvTranspose1d(32, 16, 8, 2, padding=3)
#         self.conv4 = nn.ConvTranspose1d(16, 16, 8, 2, padding=3)
#         self.conv5 = nn.ConvTranspose1d(16, 1, 7, 1, padding=3)
#         self.relu = nn.ReLU()

#     def forward(self, z):
#         z = self.relu(self.fc1(z))
#         z = z.view(-1, 32, 21)
#         z = self.relu(self.conv1(z))
#         z = self.relu(self.conv2(z))
#         z = self.relu(self.conv3(z))
#         z = self.relu(self.conv4(z))
#         z = self.conv5(z)
#         recon = torch.sigmoid(z)
#         return recon


# class CNNVAE(nn.Module):
#     def __init__(self, z_dim=2):
#         super(VAE, self).__init__()
#         self.encoder = Encoder(z_dim)
#         self.decoder = Decoder(z_dim)
#         self.cuda()
#         self.z_dim = z_dim

#     def reparameterize(self, z_loc, z_scale):
#         std = z_scale.mul(0.5).exp_()
#         epsilon = torch.randn(*z_loc.size()).to(device)
#         z = z_loc + std * epsilon
#         return z


# INPUT_SIZE = 1200
# LATENT_DIMS = 2
# EPOCHS = 20

# def train(vae, data, epochs=EPOCHS):
#     opt = torch.optim.Adam(vae.parameters())
#     for epoch in range(epochs):
#         for x, y in data:
#             x = x.to(DEVICE)

#             opt.zero_grad()

#             mu, log_var = vae.encoder(x)
#             z = vae.reparameterize(mu, log_var)
#             x_hat = vae.decoder(z)
#             loss = vae.loss_fn(x_hat, x, mu, log_var)

#             loss.backward()
#             opt.step()
#     return vae

# DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
# data, _ = build_dataloaders()

# vae = CNNVariationalAutoencoder(INPUT_SIZE, LATENT_DIMS).to(DEVICE)
# vae = train(vae, data)

# plot_latent2(vae, data, DEVICE)


# ===================================================

class Encoder(nn.Module):
    def __init__(self, z_dim):
        super(Encoder, self).__init__()
        self.conv1 = nn.Conv1d(1, 16, 8, 2, padding=3)
        self.conv2 = nn.Conv1d(16, 16, 8, 2, padding=3)
        self.conv3 = nn.Conv1d(16, 32, 8, 2, padding=3)
        self.conv4 = nn.Conv1d(32, 32, 8, 2, padding=3)

        self.fc1 = nn.Linear(32*75, 64)
        # self.fc1 = nn.Linear(240000, 64)
        self.fc2 = nn.Linear(64, 16)
        self.fc21 = nn.Linear(16, z_dim)
        self.fc22 = nn.Linear(16, z_dim)
        self.relu = nn.ReLU()


    def forward(self, x):
        # x = x.view(-1,1,336)
        print('1...')
        print(x.shape)
        x = x.view(-1,1,1200)
        # x = torch.flatten(x, start_dim=1)
        # print(x.shape)
        x = self.relu(self.conv1(x))
        print('2...')
        print(x.shape)
        
        x = self.relu(self.conv2(x))
        print('3...')
        print(x.shape)
        
        x = self.relu(self.conv3(x))
        print('4...')
        print(x.shape)
        
        x = self.relu(self.conv4(x))
        print("5...")
        print(x.shape)

        # x = x.view(-1, 1, 240000)
        x = x.view(-1, 32*75)
        x = self.relu(self.fc1(x))
        x = F.dropout(x, 0.3)
        x = self.relu(self.fc2(x))

        z_loc = self.fc21(x)
        z_scale = self.fc22(x)

        print("6...")
        print(x.shape)

        print("6...z_loc")
        print(z_loc.shape)
        print("6...z_scale")
        print(z_scale.shape)
        return z_loc, z_scale

class Decoder(nn.Module):
    def __init__(self, z_dim):
        super(Decoder, self).__init__()
        self.fc1 = nn.Linear(z_dim, 32*75)
        self.conv1 = nn.ConvTranspose1d(32, 32, 8, 2, padding=3)
        self.conv2 = nn.ConvTranspose1d(32, 32, 8, 2, padding=3)
        self.conv3 = nn.ConvTranspose1d(32, 16, 8, 2, padding=3)
        self.conv4 = nn.ConvTranspose1d(16, 16, 8, 2, padding=3)
        self.conv5 = nn.ConvTranspose1d(16, 1, 7, 1, padding=3)
        self.relu = nn.ReLU()

    def forward(self, z):

        print("7...")
        print(z.shape)
        z = self.relu(self.fc1(z))
        # z = z.view(-1, 240000)
        print("8...")
        print(z.shape)
        z = z.view(-1, 32, 75)

        print("9...")
        print(z.shape)
        
        z = self.relu(self.conv1(z))
        print("10...")
        print(z.shape)
        
        z = self.relu(self.conv2(z))
        z = self.relu(self.conv3(z))
        z = self.relu(self.conv4(z))
        z = self.conv5(z)
        recon = torch.sigmoid(z)
        return recon



class CNNVariationalAutoencoder(nn.Module):
    def __init__(self, latent_dims):
        super(CNNVariationalAutoencoder, self).__init__()
        self.decoder = Decoder(latent_dims)
        self.encoder = Encoder(latent_dims)

    def forward(self, x):
        mu, log_var = self.encoder(x)
        z = self.reparameterize(mu, log_var)
        x_hat = self.decoder(z)

        return x_hat, mu, log_var

    def loss_fn(self, x_hat, x, mu, log_var):
        # x = x.view(x.size(0), -1) 
        x = x.view(-1,1200)
        x_hat = x_hat.view(-1,1200)
        # x = torch.flatten(x, start_dim=1)
        print('x_hat')
        print(x_hat.shape)
        print('x')
        print(x.shape)
        
        MSE = F.binary_cross_entropy(x_hat, x, size_average=False)
        # MSE = F.mse_loss(x_hat, x, size_average=False)*10
        KLD = -0.5 * torch.mean(1 + log_var - mu.pow(2) - log_var.exp())
        return MSE + KLD

    def reparameterize(self, mu, log_var): 
        std = torch.exp(log_var/2)
        eps = torch.randn_like(std)
        return mu + eps * std


# INPUT_SIZE = 1200
LATENT_DIMS = 2
EPOCHS = 520

def train(model, data, epochs=EPOCHS):
    opt = torch.optim.Adam(model.parameters())
    for epoch in range(epochs):
        for x, y in data:
            x = x.to(DEVICE)

            opt.zero_grad()

            # mu, log_var = model.encoder(x)
            # z = model.reparameterize(mu, log_var)

            x_hat, mu, log_var = model(x)
            loss = model.loss_fn(x_hat, x, mu, log_var)

            loss.backward()
            opt.step()
    return model

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
data, _ = build_dataloaders()

model = CNNVariationalAutoencoder(LATENT_DIMS).to(DEVICE)
model = train(model, data)

plot_latent2(model, data, DEVICE)